{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90d5bff5-79c0-4a4b-a7cf-54c872c93007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 1875, loss is 0.05679894983768463\n",
      "epoch: 2 step: 1875, loss is 0.10386011004447937\n",
      "epoch: 3 step: 1875, loss is 0.005582510028034449\n",
      "epoch: 4 step: 1875, loss is 0.0019453082932159305\n",
      "epoch: 5 step: 1875, loss is 0.0004732749657705426\n",
      "epoch: 6 step: 1875, loss is 0.0005306907114572823\n",
      "epoch: 7 step: 1875, loss is 0.07282890379428864\n",
      "epoch: 8 step: 1875, loss is 0.00039607385406270623\n",
      "epoch: 9 step: 1875, loss is 3.834067319985479e-05\n",
      "epoch: 10 step: 1875, loss is 0.00044187414459884167\n",
      "Accuracy: 0.9896834935897436\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mindspore as ms\n",
    "# 导入mindspore中context模块，用于配置当前执行环境，包括执行模式等特性。\n",
    "import mindspore.context as context\n",
    "# c_transforms模块提供常用操作，包括OneHotOp和TypeCast\n",
    "import mindspore.dataset.transforms as C\n",
    "# vision.c_transforms模块是处理图像增强的高性能模块，用于数据增强图像数据改进训练模型。\n",
    "import mindspore.dataset.vision as CV\n",
    "import numpy as np\n",
    "from mindspore import nn\n",
    "from mindspore.nn import Accuracy\n",
    "from mindspore.train import Model\n",
    "from mindspore.train.callback import LossMonitor\n",
    "import matplotlib.pyplot as plt\n",
    "# 设置MindSpore的执行模式和设备\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target='CPU') # Ascend, CPU, GPU\n",
    " \n",
    "def create_dataset(data_dir, training=True, batch_size=32, resize=(32, 32),\n",
    "                   rescale=1/(255*0.3081), shift=-0.1307/0.3081, buffer_size=64):\n",
    "    data_train = os.path.join(data_dir, 'train') # 训练集信息\n",
    "    data_test = os.path.join(data_dir, 'test') # 测试集信息\n",
    "    ds = ms.dataset.MnistDataset(data_train if training else data_test)\n",
    "    ds = ds.map(input_columns=[\"image\"], operations=[CV.Resize(resize), CV.Rescale(rescale, shift), CV.HWC2CHW()])\n",
    "    ds = ds.map(input_columns=[\"label\"], operations=C.TypeCast(ms.int32))\n",
    "    ds = ds.shuffle(buffer_size=buffer_size).batch(batch_size, drop_remainder=True)\n",
    "    return ds\n",
    " \n",
    "ds = create_dataset(r'C:\\Users\\19616\\MNIST_Data', training=False)\n",
    "# data = ds.create_dict_iterator()\n",
    "# for da in data:\n",
    "#     print(da['image'].type())\n",
    "# images = data['image'].asnumpy()\n",
    "# labels = data['label'].asnumpy()\n",
    "# #显示前4张图片以及对应标签\n",
    "# for i in range(1, 5):\n",
    "#     plt.subplot(2, 2, i)\n",
    "#     plt.imshow(images[i][0])\n",
    "#     plt.title('Number: %s' % labels[i])\n",
    "#     plt.xticks([])\n",
    "# plt.show()\n",
    " \n",
    "#定义LeNet5模型\n",
    "class LeNet5(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5, pad_mode='valid')\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5, pad_mode='valid')\n",
    "        self.relu = nn.ReLU()\n",
    "        self.max_pool2d = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Dense(16*5*5, 120)\n",
    "        self.fc2 = nn.Dense(120, 84)\n",
    "        self.fc3 = nn.Dense(84, 10)\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.max_pool2d(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.max_pool2d(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    " \n",
    "def train(data_dir, lr=0.01, momentum=0.9, num_epochs=10):\n",
    "    ds_train = create_dataset(data_dir)\n",
    "    ds_eval = create_dataset(data_dir, training=False)\n",
    "    net = LeNet5()\n",
    "    #计算softmax交叉熵。\n",
    "    loss = nn.loss.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
    "    #设置Momentum优化器\n",
    "    opt = nn.Momentum(net.trainable_params(), lr, momentum)\n",
    "    \n",
    "    loss_cb = LossMonitor(per_print_times=ds_train.get_dataset_size())\n",
    "    \n",
    "    model = Model(net, loss, opt, metrics={\"Accuracy\": Accuracy()})\n",
    "    \n",
    "    model.train(num_epochs, ds_train, callbacks=[loss_cb], dataset_sink_mode=True)\n",
    "\n",
    "    \n",
    "    metrics_result = model.eval(ds_eval)\n",
    "    \n",
    "    print('Accuracy:',metrics_result[\"Accuracy\"])\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "train(r'C:\\Users\\19616\\MNIST_Data')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6d6cd6-511e-4e82-bd20-04731663b268",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
